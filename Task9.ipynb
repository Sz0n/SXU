{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, glob, random, math\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(message):\n",
    "    message = message.lower()                   #Zamień na małe litery.\n",
    "    all_words = re.findall(\"[a-z0-9]+\",message) #Wyciągnij slowa.\n",
    "    return set(all_words)                       #Usuń duplikaty.\n",
    "\n",
    "def count_words(training_set):\n",
    "    \"\"\"zbior treningowy to para (message,is_spam)\"\"\"\n",
    "    counts = defaultdict(lambda: [0,0])\n",
    "    for message, is_spam in training_set:\n",
    "        for word in tokenize(message):\n",
    "            counts[word][0 if is_spam else 1] += 1\n",
    "    return counts\n",
    "\n",
    "def word_probabilities(counts,total_spams,total_non_spams,k=0.5):\n",
    "    \"\"\"zwrocenie 3-elementowej listy zawierajace slowo, prawdopodobienstwo wystapienia w spamie i prawdopodobienstwa nie bycia spamem\"\"\"\n",
    " \n",
    "    return [(w,(spam +k)/(total_spams + 2 *k),\n",
    "            (non_spam + k)/(total_non_spams +2 * k))\n",
    "            for w,(spam,non_spam) in counts.items()]\n",
    "\n",
    "def spam_probability(word_probs, message):\n",
    "    \"\"\"prawdopodbienstwo wystapienia slow w celu przypisania prawdopodobienstw do wiadomosci\"\"\"\n",
    "    message_words = tokenize(message)\n",
    "    log_prob_if_spam = log_prob_if_not_spam = 0.0\n",
    "\n",
    "    for word, prob_if_spam, prob_if_not_spam in word_probs:\n",
    "        if word in message_words:\n",
    "            log_prob_if_spam += math.log(prob_if_spam)\n",
    "            log_prob_if_not_spam += math.log(prob_if_not_spam)\n",
    "        else:\n",
    "            log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "            log_prob_if_not_spam += math.log(1.0 - prob_if_not_spam)\n",
    "\n",
    "    prob_if_spam = math.exp(log_prob_if_spam)\n",
    "    prob_if_not_spam = math.exp(log_prob_if_not_spam)\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self,k=0.5):\n",
    "        self.k = k\n",
    "        self.word_probs = []\n",
    "        \n",
    "    def train(self,training_set):\n",
    "        num_spams = len([is_spam for message, is_spam in training_set if is_spam])\n",
    "        num_non_spams = len(training_set) - num_spams\n",
    "        \n",
    "        #Przetwórz treningowy zbiór danych\n",
    "        word_counts = count_words(training_set)\n",
    "        self.word_probs = word_probabilities(word_counts,num_spams,num_non_spams,self.k)\n",
    "        \n",
    "    def classify(self,message):\n",
    "        return spam_probability(self.word_probs,message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\kamil\\data_science\\spam*\\\\*\\\\**\"\n",
    "\n",
    "data = []\n",
    "\n",
    "for fn in glob.glob(path):\n",
    "    is_spam = \"ham\" not in fn\n",
    "\n",
    "    with open(fn,'r',encoding='ISO-8859-1') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"Subject:\"):\n",
    "                subject = re.sub(r\"^Subject: \",\"\", line).strip()\n",
    "                data.append((subject, is_spam))\n",
    "\n",
    "#metoda z pliku machine_learning\n",
    "def split_data(data, prob):\n",
    "    \"\"\"split data into fractions [prob, 1 - prob]\"\"\"\n",
    "    results = [], []\n",
    "    for row in data:\n",
    "        results[0 if random.random() < prob else 1].append(row)\n",
    "    return results\n",
    "\n",
    "#dodatkowa metoda, ktora na podstawie twierdzenia bayesa oblicza prawdopodobienstwa spamu\n",
    "def p_spam_given_word(word_prob):\n",
    "    word, prob_if_spam, prob_if_not_spam = word_prob\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spammiest_hams: \n",
      " [('Buy Ryanair Travel Insurance Today', False, 0.9388516349179015), ('Automated 30 day renewal reminder 2002-05-27', False, 0.9518481976548178), ('Are bigger notebooks better?', False, 0.9535929614593901), ('\"I meditated in a cave for 12 years and now I\\'m here to tell you', False, 0.9838874066074335), ('FREE SHIPPING! No Minimum Purchase* at Buy.com', False, 0.9909761026638615)] \n",
      "\n",
      "hammiest_spams \n",
      " [('Place Your LTC Declines with Us', True, 0.0056621575326712865), ('The Flight to Safety is Upon Us', True, 0.006312066148419511), ('Lease Deal', True, 0.007456610072298607), ('Looking for property in SPAIN?', True, 0.01072369258736404), ('Outstanding Opportunities for \"Premier Producers\"', True, 0.01114127099442387)] \n",
      "\n",
      "spammiest_words \n",
      " [('zzzz', 0.026785714285714284, 0.00021872265966754156), ('sale', 0.029336734693877552, 0.00021872265966754156), ('money', 0.029336734693877552, 0.00021872265966754156), ('systemworks', 0.03188775510204082, 0.00021872265966754156), ('adv', 0.047193877551020405, 0.00021872265966754156)] \n",
      "\n",
      "hammiest_words \n",
      " [('spambayes', 0.0012755102040816326, 0.048337707786526685), ('zzzzteana', 0.0012755102040816326, 0.047900262467191604), ('satalk', 0.0012755102040816326, 0.04615048118985127), ('users', 0.0012755102040816326, 0.03740157480314961), ('razor', 0.0012755102040816326, 0.03215223097112861)]\n"
     ]
    }
   ],
   "source": [
    "#podzielenie zbioru na treningowy i testowy oraz zbudowanie klasyfikatora\n",
    "random.seed(0)\n",
    "train_data,test_data = split_data(data,0.8)\n",
    "\n",
    "classifier = NaiveBayesClassifier()\n",
    "classifier.train(train_data)\n",
    "\n",
    "classified = [(subject, is_spam,classifier.classify(subject)) for subject,is_spam in test_data]\n",
    "counts = Counter((is_spam,spam_probability > 0.5) for _,is_spam,spam_probability in classified)\n",
    "\n",
    "classified.sort(key=lambda row: row[2])\n",
    "#Największe prawdopodbieństwo spamu uzyskane wsród wiadomości niebedacych spamem\n",
    "\n",
    "spammiest_hams = list(filter(lambda row: not row[1], classified))[-5:]\n",
    "\n",
    "#Najmniejsze spamu uzyskane wsród wiadomości niebedacych spamem\n",
    "\n",
    "hammiest_spams = list(filter(lambda row: row[1], classified))[:5]\n",
    "\n",
    "words = sorted(classifier.word_probs, key=p_spam_given_word)\n",
    "\n",
    "#najwieksze prawdopodbieństwo że wiadomość jest spamem\n",
    "spammiest_words = words[-5:]\n",
    "#Najwieksze prawdopodbieństwo że wiadomość nie jest spamem\n",
    "hammiest_words = words[:5]\n",
    "\n",
    "print(\"spammiest_hams:\",'\\n', spammiest_hams,'\\n')\n",
    "print(\"hammiest_spams\",'\\n', hammiest_spams,'\\n')\n",
    "print(\"spammiest_words\",'\\n', spammiest_words,'\\n')\n",
    "print(\"hammiest_words\",'\\n', hammiest_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
